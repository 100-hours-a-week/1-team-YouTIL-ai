version: "3"
services:
  vllm:
    image: vllm/vllm-openai
    ports:
      - "8001:8001"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGINGFACE_TOKEN}
    # volumes:
    #   - /home/a01088415234/models/gemma-3-4b-it:/models/gemma
    command: >
      --model google/gemma-3-4b-it
      --port 8001
      --gpu-memory-utilization 0.8
      --max-model-len 4096
      --max-num-seqs 50
      --max-num-batched-tokens 4096
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]