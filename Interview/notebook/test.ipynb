{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37a3115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-04 15:00:09 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='/home/yuri011228/ai2-server/models/mistral-7b', speculative_config=None, tokenizer='/home/yuri011228/ai2-server/models/mistral-7b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/yuri011228/ai2-server/models/mistral-7b, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 05-04 15:00:09 model_runner.py:1056] Starting to load model /home/yuri011228/ai2-server/models/mistral-7b...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 21.95 GiB of which 193.25 MiB is free. Process 32495 has 20.53 GiB memory in use. Including non-PyTorch memory, this process has 1.09 GiB memory in use. Of the allocated memory 892.00 MiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m mistral \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/yuri011228/ai2-server/models/mistral-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m AsyncEngineArgs(\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39mmistral,\n\u001b[1;32m      7\u001b[0m     tensor_parallel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# GPU 개수\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     max_model_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4096\u001b[39m, \u001b[38;5;66;03m# input + output 토큰 길이\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     max_num_batched_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m) \n\u001b[0;32m---> 13\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAsyncLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/engine/async_llm_engine.py:672\u001b[0m, in \u001b[0;36mAsyncLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, engine_config, start_engine_loop, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    669\u001b[0m     initialize_ray_cluster(engine_config\u001b[38;5;241m.\u001b[39mparallel_config)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Create the async LLM engine.\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_requests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_requests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_engine_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_engine_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/engine/async_llm_engine.py:567\u001b[0m, in \u001b[0;36mAsyncLLMEngine.__init__\u001b[0;34m(self, log_requests, start_engine_loop, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    562\u001b[0m              \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    563\u001b[0m              log_requests: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    564\u001b[0m              start_engine_loop: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    565\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_requests \u001b[38;5;241m=\u001b[39m log_requests\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;66;03m# This ensures quick processing of request outputs\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# so the append to asyncio queues is not delayed,\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# especially for multi-step.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_process_request_outputs_callback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39muse_async_output_proc)\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/engine/async_llm_engine.py:263\u001b[0m, in \u001b[0;36m_AsyncLLMEngine.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/engine/llm_engine.py:334\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, decoding_config, observability_config, prompt_adapter_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, use_cached_outputs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_registry \u001b[38;5;241m=\u001b[39m input_registry\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_processor \u001b[38;5;241m=\u001b[39m input_registry\u001b[38;5;241m.\u001b[39mcreate_input_processor(\n\u001b[1;32m    332\u001b[0m     model_config)\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeculative_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeculative_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_adapter_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_adapter_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservability_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservability_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39membedding_mode:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/executor/executor_base.py:47\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, prompt_adapter_config, observability_config)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_adapter_config \u001b[38;5;241m=\u001b[39m prompt_adapter_config\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;241m=\u001b[39m observability_config\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/executor/gpu_executor.py:40\u001b[0m, in \u001b[0;36mGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_worker()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker\u001b[38;5;241m.\u001b[39minit_device()\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/worker/worker.py:183\u001b[0m, in \u001b[0;36mWorker.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/worker/model_runner.py:1058\u001b[0m, in \u001b[0;36mGPUModelRunnerBase.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1056\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting to load model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DeviceMemoryProfiler() \u001b[38;5;28;01mas\u001b[39;00m m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mconsumed_memory\n\u001b[1;32m   1067\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model weights took \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1068\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m))\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/model_loader/__init__.py:19\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, load_config, device_config, parallel_config, scheduler_config, lora_config, cache_config)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_model\u001b[39m(\u001b[38;5;241m*\u001b[39m, model_config: ModelConfig, load_config: LoadConfig,\n\u001b[1;32m     14\u001b[0m               device_config: DeviceConfig, parallel_config: ParallelConfig,\n\u001b[1;32m     15\u001b[0m               scheduler_config: SchedulerConfig,\n\u001b[1;32m     16\u001b[0m               lora_config: Optional[LoRAConfig],\n\u001b[1;32m     17\u001b[0m               cache_config: CacheConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m     18\u001b[0m     loader \u001b[38;5;241m=\u001b[39m get_model_loader(load_config)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/model_loader/loader.py:398\u001b[0m, in \u001b[0;36mDefaultModelLoader.load_model\u001b[0;34m(self, model_config, device_config, lora_config, parallel_config, scheduler_config, cache_config)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_default_torch_dtype(model_config\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m target_device:\n\u001b[0;32m--> 398\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43m_initialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_weights(model_config, model))\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/model_loader/loader.py:175\u001b[0m, in \u001b[0;36m_initialize_model\u001b[0;34m(model_config, load_config, lora_config, cache_config, scheduler_config)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize a model with the given configurations.\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m model_class, _ \u001b[38;5;241m=\u001b[39m get_model_architecture(model_config)\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_quantization_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultimodal_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultimodal_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/model_loader/loader.py:160\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(model_class, hf_config, cache_config, quant_config, lora_config, multimodal_config, scheduler_config)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_model\u001b[39m(model_class: Type[nn\u001b[38;5;241m.\u001b[39mModule], hf_config: PretrainedConfig,\n\u001b[1;32m    151\u001b[0m                 cache_config: Optional[CacheConfig],\n\u001b[1;32m    152\u001b[0m                 quant_config: Optional[QuantizationConfig], \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    153\u001b[0m                 lora_config: Optional[LoRAConfig],\n\u001b[1;32m    154\u001b[0m                 multimodal_config: Optional[MultiModalConfig],\n\u001b[1;32m    155\u001b[0m                 scheduler_config: Optional[SchedulerConfig]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m    156\u001b[0m     extra_kwargs \u001b[38;5;241m=\u001b[39m _get_model_initialization_kwargs(model_class, lora_config,\n\u001b[1;32m    157\u001b[0m                                                     multimodal_config,\n\u001b[1;32m    158\u001b[0m                                                     scheduler_config)\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/models/llama.py:515\u001b[0m, in \u001b[0;36mLlamaForCausalLM.__init__\u001b[0;34m(self, config, cache_config, quant_config, lora_config)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_config \u001b[38;5;241m=\u001b[39m lora_config\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpadded_vocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/models/llama.py:305\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, config, cache_config, quant_config, lora_config, prefix)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m PPMissingLayer()\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m \u001b[43mmake_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLlamaDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.layers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/models/utils.py:419\u001b[0m, in \u001b[0;36mmake_layers\u001b[0;34m(num_hidden_layers, layer_fn, prefix)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_pp_indices\n\u001b[1;32m    415\u001b[0m start_layer, end_layer \u001b[38;5;241m=\u001b[39m get_pp_indices(num_hidden_layers,\n\u001b[1;32m    416\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mrank_in_group,\n\u001b[1;32m    417\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mworld_size)\n\u001b[1;32m    418\u001b[0m modules \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 419\u001b[0m     [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer)] \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m    420\u001b[0m         maybe_offload_to_cpu(layer_fn(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer, end_layer)\n\u001b[1;32m    422\u001b[0m     ] \u001b[38;5;241m+\u001b[39m [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/models/utils.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_pp_indices\n\u001b[1;32m    415\u001b[0m start_layer, end_layer \u001b[38;5;241m=\u001b[39m get_pp_indices(num_hidden_layers,\n\u001b[1;32m    416\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mrank_in_group,\n\u001b[1;32m    417\u001b[0m                                         get_pp_group()\u001b[38;5;241m.\u001b[39mworld_size)\n\u001b[1;32m    418\u001b[0m modules \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m    419\u001b[0m     [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer)] \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m--> 420\u001b[0m         maybe_offload_to_cpu(\u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer, end_layer)\n\u001b[1;32m    422\u001b[0m     ] \u001b[38;5;241m+\u001b[39m [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/models/llama.py:307\u001b[0m, in \u001b[0;36mLlamaModel.__init__.<locals>.<lambda>\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m PPMissingLayer()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m make_layers(\n\u001b[1;32m    306\u001b[0m     config\u001b[38;5;241m.\u001b[39mnum_hidden_layers,\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m prefix: \u001b[43mLlamaDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    311\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.layers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    312\u001b[0m )\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/models/llama.py:231\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[0;34m(self, config, cache_config, quant_config, prefix)\u001b[0m\n\u001b[1;32m    215\u001b[0m attention_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    216\u001b[0m     config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m LlamaAttention(\n\u001b[1;32m    218\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    219\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.self_attn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m )\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaMLP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_act\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_act\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    240\u001b[0m                                eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    242\u001b[0m                                         eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/models/llama.py:73\u001b[0m, in \u001b[0;36mLlamaMLP.__init__\u001b[0;34m(self, hidden_size, intermediate_size, hidden_act, quant_config, bias, prefix)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     65\u001b[0m     hidden_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_up_proj \u001b[38;5;241m=\u001b[39m \u001b[43mMergedColumnParallelLinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mintermediate_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.gate_up_proj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj \u001b[38;5;241m=\u001b[39m RowParallelLinear(\n\u001b[1;32m     81\u001b[0m         input_size\u001b[38;5;241m=\u001b[39mintermediate_size,\n\u001b[1;32m     82\u001b[0m         output_size\u001b[38;5;241m=\u001b[39mhidden_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m         prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.down_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hidden_act \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/layers/linear.py:424\u001b[0m, in \u001b[0;36mMergedColumnParallelLinear.__init__\u001b[0;34m(self, input_size, output_sizes, bias, gather_output, skip_bias_add, params_dtype, quant_config, prefix)\u001b[0m\n\u001b[1;32m    422\u001b[0m tp_size \u001b[38;5;241m=\u001b[39m get_tensor_model_parallel_world_size()\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(output_size \u001b[38;5;241m%\u001b[39m tp_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output_size \u001b[38;5;129;01min\u001b[39;00m output_sizes)\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mgather_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgather_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mskip_bias_add\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bias_add\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/layers/linear.py:304\u001b[0m, in \u001b[0;36mColumnParallelLinear.__init__\u001b[0;34m(self, input_size, output_size, bias, gather_output, skip_bias_add, params_dtype, quant_config, output_sizes, prefix)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     output_sizes \u001b[38;5;241m=\u001b[39m [output_size]\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_loader_v2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mWEIGHT_LOADER_V2_SUPPORTED\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m    316\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size_per_partition,\n\u001b[1;32m    317\u001b[0m                     dtype\u001b[38;5;241m=\u001b[39mparams_dtype))\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/vllm/model_executor/layers/linear.py:122\u001b[0m, in \u001b[0;36mUnquantizedLinearMethod.create_weights\u001b[0;34m(self, layer, input_size_per_partition, output_partition_sizes, input_size, output_size, params_dtype, **extra_weight_attrs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m    118\u001b[0m                    input_size_per_partition: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    119\u001b[0m                    output_partition_sizes: List[\u001b[38;5;28mint\u001b[39m], input_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    120\u001b[0m                    output_size: \u001b[38;5;28mint\u001b[39m, params_dtype: torch\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    121\u001b[0m                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_weight_attrs):\n\u001b[0;32m--> 122\u001b[0m     weight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    125\u001b[0m                        requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    126\u001b[0m     set_weight_attrs(weight, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m})\n\u001b[1;32m    127\u001b[0m     layer\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight)\n",
      "File \u001b[0;32m~/1-team-YouTIL-ai/Interview/venv/lib/python3.8/site-packages/torch/utils/_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 21.95 GiB of which 193.25 MiB is free. Process 32495 has 20.53 GiB memory in use. Including non-PyTorch memory, this process has 1.09 GiB memory in use. Of the allocated memory 892.00 MiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from vllm import AsyncEngineArgs, AsyncLLMEngine\n",
    "\n",
    "mistral = \"/home/yuri011228/ai2-server/models/mistral-7b\"\n",
    "\n",
    "engine_args = AsyncEngineArgs(\n",
    "    model=mistral,\n",
    "    tensor_parallel_size=1, # GPU 개수\n",
    "    gpu_memory_utilization=0.95,\n",
    "    max_num_seqs = 100, # 동시에 받을 수 있는 요청 개수\n",
    "    max_model_len=4096, # input + output 토큰 길이\n",
    "    max_num_batched_tokens=8192) \n",
    "\n",
    "llm = AsyncLLMEngine.from_engine_args(engine_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62598b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      4\u001b[0m load_dotenv()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ HOST:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQDRANT_HOST\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ HOST:\", os.getenv(\"QDRANT_HOST\"))\n",
    "print(\"✅ PORT:\", os.getenv(\"QDRANT_PORT\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccb697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"]  # 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29ee368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = {\n",
    "  \"email\": \"ConconDev\",\n",
    "  \"date\": \"2024-09-06\",\n",
    "  \"level\": \"1\",\n",
    "  \"title\": \"알람 구독 서비스 개선: SseEmitter 활용 및 사용자별 Emitter 관리\",\n",
    "  \"keywords\": [\n",
    "    \"SSE\",\n",
    "    \"SseEmitter\",\n",
    "    \"알람 구독\",\n",
    "    \"사용자별 관리\"\n",
    "  ],\n",
    "  \"til\": \"# 알람 구독 서비스 개선: SseEmitter 활용 및 사용자별 Emitter 관리\\n\\n## 1. 오늘 배운 내용\\n\\n오늘 저는 알람 구독 서비스를 개선하기 위해 `SseEmitter`를 활용하고, 각 사용자별로 `SseEmitter`를 저장하고 관리하는 기능을 구현했습니다.  `SseEmitter`는 서버에서 클라이언트로 실시간 데이터를 스트리밍하는 데 유용한 API입니다.\\n\\n## 2. 개념 정리\\n\\n*   **SSE (Server-Sent Events):** 서버에서 클라이언트로 단방향 통신을 가능하게 하는 웹 기술입니다. 서버가 새로운 이벤트 발생 시 클라이언트에게 자동으로 업데이트를 전송합니다.\\n*   **SseEmitter:** SSE 통신을 위한 객체입니다.  데이터를 발행하거나, 연결을 종료하거나, 오류를 처리하는 등의 기능을 제공합니다.\\n*   **ConcurrentHashMap:** 여러 스레드에서 동시에 접근해도 안전하게 데이터를 저장하고 검색할 수 있는 해시맵입니다.  여기서는 사용자 ID를 키로 하고 `SseEmitter`를 값으로 저장하는 데 사용되었습니다.\\n\\n## 3. 해당 개념이 필요한 이유\\n\\n기존 알람 구독 방식은 클라이언트가 주기적으로 서버에 요청을 보내는 방식으로, 서버 부하가 심하고 효율성이 떨어졌습니다. `SseEmitter`를 사용하면 서버는 새로운 알람이 발생했을 때만 클라이언트에 데이터를 전송하므로, 서버 자원을 절약하고 실시간성을 높일 수 있습니다. 또한, 사용자별로 `SseEmitter`를 관리함으로써, 특정 사용자에 대한 알람만 전송하도록 할 수 있어 더욱 효율적인 알람 구독 시스템을 구축할 수 있습니다.\\n\\n## 4. 개념을 활용하는 방법\\n\\n1.  `SseEmitter` 객체를 생성하고 초기화합니다.\\n2.  사용자 ID를 키로, `SseEmitter` 객체를 값으로 `ConcurrentHashMap`에 저장합니다.\\n3.  클라이언트에서 SSE 연결을 설정하고, 서버로부터 데이터를 수신합니다.\\n4.  사용자가 알람 구독/취소 요청을 하면, 해당 사용자의 `SseEmitter`를 업데이트하거나 삭제합니다.\\n\\n## 5. 문제 해결 과정\\n\\n*   처음에는 `SseEmitter`의 생명주기를 제대로 관리하지 못하여 메모리 누수가 발생했습니다.  `SseEmitter` 객체의 `close()` 메서드를 호출하여 리소스 누수를 방지했습니다.\\n*   사용자 ID 중복 문제를 해결하기 위해 사용자 ID를 키로 사용하는 `ConcurrentHashMap`을 사용했습니다.\\n*   클라이언트에서 SSE 연결을 안정적으로 유지하기 위해 에러 핸들링 로직을 추가했습니다.\\n\\n## 6. 하루 회고\\n\\n오늘은 알람 구독 서비스의 성능 개선을 위해 중요한 기술인 `SseEmitter`를 익히고 적용하는 시간을 가졌습니다.  `SseEmitter`의 동작 원리를 이해하고, 실제 서비스에 적용하면서 많은 어려움을 겪었지만, 결국 성공적으로 구현할 수 있었습니다. 앞으로는 `SseEmitter`를 더 깊이 이해하고, 다양한 응용 분야에 적용해보고 싶습니다.\\n\\n## 7. 전체적으로 개조식 문장 구성\\n\\n*   **목표:** 알람 구독 서비스의 실시간성 및 효율성 향상\\n*   **핵심 기술:** SSE, SseEmitter, ConcurrentHashMap\\n*   **구현 단계:**\\n    *   `SseEmitter` 객체 생성 및 초기화\\n    *   사용자별 `SseEmitter` 저장 및 관리 (`ConcurrentHashMap`) \\n    *   SSE 연결 설정 및 데이터 수신\\n    *   알람 구독/취소 요청 처리\\n    *   메모리 누수 방지 및 에러 핸들링\\n\\n\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbeec89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"\n",
    "당신은 사용자의 기술 학습 기록을 바탕으로, 기술 면접에 적합한 질문과 답변을 생성하는 AI입니다.\n",
    "\n",
    "아래 정보를 참고하여,\n",
    "[TIL 본문] {til}\n",
    "[선택한 난이도] {level}\n",
    "\n",
    "- 먼저 면접 질문을 만들고, 그 다음 해당 질문에 대한 답변을 작성해주세요.\n",
    "\n",
    "※ level에 따라 질문과 답변의 깊이를 조절하세요:\n",
    "- level \"1\": 깊은 기술 이해와 실무 경험 기반 질문\n",
    "- level \"2\": 개념적 이해를 묻는 질문\n",
    "- level \"3\": 기본 개념을 묻는 질문\n",
    "\n",
    "단 **3개**의 질문과 각 질문에 대한 답변을 작성하세요.\n",
    "모든 질문과 답변은 반드시 **한국어**로 작성하세요.\n",
    "\n",
    "반드시, 아래와 같은 형식으로 3개의 질문과 답변을 출력하세요.\n",
    "\n",
    "question: 질문1\n",
    "answer: 답변1\n",
    "\n",
    "question: 질문2\n",
    "answer: 답변2\n",
    "\n",
    "question: 질문3\n",
    "answer: 답변3\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a71449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class ContentState(BaseModel):\n",
    "    question: str\n",
    "    answer: str \n",
    "\n",
    "class QAState(BaseModel):\n",
    "    email: str\n",
    "    date: str\n",
    "    level: int\n",
    "    title: str\n",
    "    keywords: List[str]\n",
    "    til: str\n",
    "    \n",
    "    answer_raw: Optional[str] = None\n",
    "\n",
    "    summary: Optional[str] = None\n",
    "    content: Optional[List[ContentState]] = None\n",
    "\n",
    "qa_input = QAState(\n",
    "    email=dummy['email'],\n",
    "    date=dummy['date'],\n",
    "    level=dummy['level'],\n",
    "    title=dummy['title'],\n",
    "    keywords=dummy['keywords'],\n",
    "    til=dummy['til']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9fca709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from vllm import SamplingParams\n",
    "import json\n",
    "import re\n",
    "\n",
    "async def fallback_generate_node(state: QAState) -> dict:\n",
    "\n",
    "    prompt = prompt1.format(\n",
    "        til=state.til,\n",
    "        level=state.level\n",
    "    )\n",
    "\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        stop_token_ids=[2],  # EOS token\n",
    "    )\n",
    "\n",
    "    request_id = str(uuid4())\n",
    "    final_text = \"\"\n",
    "\n",
    "    async for output in llm.generate(\n",
    "        prompt=prompt,\n",
    "        sampling_params=sampling_params,\n",
    "        request_id=request_id\n",
    "    ):\n",
    "        final_text = output.outputs[0].text.strip()\n",
    "\n",
    "    return {\n",
    "        \"answer_raw\": final_text\n",
    "    }\n",
    "\n",
    "# async def parsing_node(state: QAState) -> dict:\n",
    "#     try:\n",
    "#         parsed = json.loads(state.answer_raw)\n",
    "#         qa_list = [ContentState(**item) for item in parsed]\n",
    "#         return {\"content\": qa_list}\n",
    "#     except Exception as e:\n",
    "#         print(f\"JSON 파싱 에러: {e}\")\n",
    "#         return {\"content\": []}\n",
    "\n",
    "async def parsing_node(state: QAState) -> dict:\n",
    "    raw = state.answer_raw\n",
    "    qa_list = []\n",
    "\n",
    "    # 정규식으로 \"question: ... answer: ...\" 패턴 추출\n",
    "    pattern = re.findall(r\"question:\\s*(.*?)\\nanswer:\\s*(.*?)(?=\\nquestion:|\\Z)\", raw, re.DOTALL)\n",
    "\n",
    "    for q, a in pattern:\n",
    "        qa_list.append(ContentState(\n",
    "            question=q.strip(),\n",
    "            answer=a.strip()\n",
    "        ))\n",
    "\n",
    "    # fallback\n",
    "    if not qa_list:\n",
    "        qa_list = [ContentState(\n",
    "            question=\"LLM 출력 파싱 실패\",\n",
    "            answer=raw.strip()\n",
    "        )]\n",
    "\n",
    "    return {\"content\": qa_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b1b8b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 생성 → 파싱 테스트 흐름\n",
    "# result = await fallback_generate_node(qa_input)\n",
    "\n",
    "# print(\"LLM 생성된 answer_raw:\")\n",
    "# print(result[\"answer_raw\"])\n",
    "# print(\"\\n---------------------------\\n\")\n",
    "\n",
    "# # QAState에 넣어서 파싱\n",
    "# qa_input.answer_raw = result[\"answer_raw\"]\n",
    "# parsed = await parsing_node(qa_input)\n",
    "\n",
    "# print(\"파싱된 결과:\")\n",
    "# for item in parsed[\"content\"]:\n",
    "#     print(\"질문\", item.question)\n",
    "#     print(\"답변\", item.answer, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f30595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-02 03:54:39 [async_llm.py:228] Added request 0b570cea-752f-4a97-ae74-c4b7e62ebed3.\n"
     ]
    }
   ],
   "source": [
    "# 그래프 정의 및 구성\n",
    "from langgraph.graph import END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "workflow = StateGraph(QAState)\n",
    "\n",
    "# 노드 선언\n",
    "workflow.add_node(\"fallback_generate\", \n",
    "    RunnableLambda(fallback_generate_node).with_config({\n",
    "        \"run_name\": \"fallback_generate\"}))\n",
    "workflow.add_node(\"parsing\",\n",
    "    RunnableLambda(parsing_node).with_config({\n",
    "        \"run_name\": \"parsing\"}))\n",
    "\n",
    "# 엣지 연결\n",
    "workflow.set_entry_point(\"fallback_generate\")\n",
    "workflow.add_edge(\"fallback_generate\", \"parsing\")\n",
    "workflow.set_finish_point(\"parsing\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "result = await graph.ainvoke(qa_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a5cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:  SSE와는 무엇이 다른가요? HTTP push 기술인 WebSocket과는 어떤 차이점이 있나요?\n",
      "답변:  SSE (Server-Sent Events)는 서버에서 단방향으로 클라이언트에 데이터를 전송하는 웹 기술입니다. WebSocket은 양방향으로 데이터를 전송할 수 있는 웹 기술입니다. 따라서, SSE는 서버가 새로운 데이터를 발생시키면 자동으로 클라이언트에게 전송하는 반면, WebSocket은 클라이언트와 서버 모두가 데이터를 송수신할 수 있습니다.\n",
      "\n",
      "\n",
      "질문:  SseEmitter를 사용하여 알람 구독 서비스를 구현하는 데 어떤 장점이 있나요?\n",
      "답변:  SseEmitter를 사용하여 알람 구독 서비스를 구현하면, 서버는 새로운 알람이 발생할 때만 클라이언트에 데이터를 전송하므로, 서버 자원을 절약하고 실시간성을 높일 수 있습니다. 또한, 사용자별로 SseEmitter를 관리함으로써, 특정 사용자에 대한 알람만 전송하도록 할 수 있어 더욱 효율적인 알람 구독 시스템을 구축할 수 있습니다.\n",
      "\n",
      "\n",
      "질문:  ConcurrentHashMap에 대해 설명해주세요.\n",
      "답변:  ConcurrentHashMap은 여러 스레드에서 동시에 접근해도 안전하게 데이터를 저장하고 검색할 수 있는 해시맵입니다. 이는 일반적인 HashMap과 달리, ConcurrentHashMap은 락을 사용하지 않고, 锁-free 또는 잠재적으로 로볼링 해싱을 사용하여 멀티 스레드 환경에서 성능을 높일 수 있습니다. 이 해시맵에서는 사용자 ID를 키로, SseEmitter 객체를 값으로 저장하여, 사용자별로 SseEmitter를 관리하고 업데이트할 수 있습니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in result[\"content\"]:\n",
    "    print(\"질문: \", item.question)\n",
    "    print(\"답변: \", item.answer)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae554f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7ff2939a8cd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09af0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이건 입력에 대한 질문입니다: LangGraph 연동 테스트'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# from langsmith import traceable\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# @traceable(name=\"generate-question\")\n",
    "# def generate_question(input_text: str) -> str:\n",
    "#     return f\"이건 입력에 대한 질문입니다: {input_text}\"\n",
    "\n",
    "# generate_question(\"LangGraph 연동 테스트\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26538afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
