services:
  vllm_gemma3_4b:
    image: vllm/vllm-openai
    ports:
      - "8002:8002"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGINGFACE_TOKEN}
    # volumes:
    #   - /home/a01088415234/models/gemma-3-4b-it:/models/gemma
    command: >
      --model google/gemma-3-4b-it
      --tokenizer google/gemma-3-4b-it
      --trust-remote-code
      --port 8002
      --gpu-memory-utilization 0.98
      --max-model-len 8096
      --max-num-seqs 30
      --max-num-batched-tokens 8096
      --enable-chunked-prefill
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]